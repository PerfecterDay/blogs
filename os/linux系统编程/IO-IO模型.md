# IO 模型
{docsify-updated}


## 阻塞IO
大部分程序使用的 I/O 模型都是单个进程每次只在一个文件描述符上执行 I/O 操作，每次I/O 系统调用都会阻塞直到完成数据传输。比如，当从一个管道中读取数据时，如果管道中恰好没有数据，那么通常 `read()` 会阻塞。而如果管道中没有足够的空间保存待写入的数据时， `write()` 也会阻塞。当在其他类型的文件如 FIFO 和套接字上执行 I/O 操作时，也会出现相似的行为。

磁盘文件是个特例。内核采用缓冲区 cache 来加速磁盘 I/O 请求。因而一旦请求的数据传输到内核的缓冲区 cache，对磁盘的 `write()` 操作将立刻返回，而不用等到将数据实际写入磁盘后才返回（除非在打开文件时指定了 `O_SYNC` 标志）。与之对应的是，`read()` 调用将数据从内核缓冲区 cache 移动到用户的缓冲区中，如果请求的数据不在内核缓冲区 cache，那么内核才会让进程休眠，同时执行对磁盘的读操作。


## 非阻塞与多线程
对于许多应用来说，传统的阻塞式I/O 模型已经足够了，但这不代表所有的应用都能得到满足。特别的，有些应用需要处理以下某项任务，或者两者都需要兼顾。
+ 如果可能的话，以非阻塞的方式检查文件描述符上是否可进行 I/O 操作。
+ 同时检查多个文件描述符，看它们中的任何一个是否可以执行 I/O 操作。

非阻塞式 I/O 和多进程/多线程技术。

### 非阻塞方案
如果在打开文件时设定了 `O_NONBLOCK` 标志，会以非阻塞方式打开文件。如果I/O 系统调用不能立刻完成，则会返回错误而不是阻塞进程。非阻塞式 I/O 可以运用到管道、FIFO、套接字、终端、伪终端以及其他一些类型的设备上。

非阻塞式 I/O 可以让我们周期性地检查（“轮询”）某个文件描述符上是否可执行 I/O 操作。比如，我们可以让一个输入文件描述符成为非阻塞式的，然后周期性地执行非阻塞式的读操作。如果我们需要同时检查多个文件描述符，那么就需要将它们都设为非阻塞，然后依次对它们轮询。**但是，这种轮询通常是我们不希望看到的。如果轮询的频率不高，那么应用程序响应I/O 事件的延时可能会达到无法接受的程度。换句话说，在一个紧凑的循环中做轮询就是在浪费 CPU。**

### 多线程方案
如果不希望进程在对文件描述符执行 I/O 操作时被阻塞，我们可以创建一个新的进程来执行 I/O。此时父进程就可以去处理其他的任务了，而子进程将阻塞直到 I/O 操作完成。如果我们需要处理多个文件描述符上的 I/O，此时可以为每个文件描述符创建一个子进程。这种方法的问题在**于开销昂贵且复杂。创建及维护进程对系统来说都有开销，而且一般来说子进程需要使用某种 IPC 机制来通知父进程有关 I/O 操作的状态。**

使用多线程而不是多进程，这将占用较少的资源。**但线程之间仍然需要通信，以告知其他线程有关I/O 操作的状态，这将使编程工作变得复杂。尤其是如果我们使用线程池技术来最小化需要处理大量并发客户的线程数量时。**（多线程特别有用的一个地方是如果应用程序需要调用一个会执行阻塞式 I/O 操作的第三方库，那么可以通过在分离的线程中调用这个库从而避免应用被阻塞。）


## IO多路复用
由于非阻塞式 I/O 和多进（线）程都有各自的局限性，下列备选方案往往更可取：
1. I/O 多路复用允许进程同时检查多个文件描述符以找出它们中的任何一个是否可执行I/O 操作。系统调用 `select()` 和 `poll()` 用来执行 I/O 多路复用。
2. 信号驱动I/O 是指当有输入或者数据可以写到指定的文件描述符上时， 内核向请求数据的进程发送一个信号。进程可以处理其他的任务，当 I/O 操作可执行时通过接收信号来获得通知。当同时检查大量的文件描述符时，信号驱动 I/O 相比 `select()` 和 `poll()` 有显著的性能提升。
3. epoll API 是Linux 专有的特性，首次出现是在Linux 2.6 版中。同I/O 多路复用API一样，epoll API 允许进程同时检查多个文件描述符，看其中任意一个是否能执行 I/O 操作。同信号驱动 I/O 一样，当同时检查大量文件描述符时，epoll 能提供更好的性能。

实际上 I/O 多路复用、 信号驱动 I/O 以及 epoll 都是用来实现同一个目标的技术—同时检查多个文件描述符，看它们是否准备好了执行 I/O 操作（准确地说，是看 I/O 系统调用是否可以非阻塞地执行）。需要注意的是**这些技术都不会执行实际的 I/O 操作。 它们只是告诉我们某个文件描述符已经处于就绪状态了，这时需要调用其他的系统调用来完成实际的 I/O 操作。**

### 不同IO复用技术对比
+ 系统调用 `select()` 和 `poll()` 在UNIX 系统中已经存在了很长的时间。同其他技术相比，它们主要的优势在于**可移植性**，主要缺点在于**当同时检查大量的（数百或数千个）文件描述符时性能延展性不佳。**
+ epoll API 的关键优势在于它能让应用程序高效地检查大量的文件描述符。其主要缺点在于它是专属于 Linux 系统的 API。
+ 同 epoll 一样，信号驱动I/O 可以让应用程序高效地检查大量的文件描述符。 但是 epoll有一些信号驱动 I/O 所没有的优点：
  + 避免了处理信号的复杂性。
  + 我们可以指定想要检查的事件类型（即，读就绪或者写就绪）。
  + 我们可以选择以水平触发或边缘触发的形式来通知进程。
  + 要完全利用信号 I/O 的优点需要用到不可移植的 Linux 专有的特性，而如果这么做了，那么信号驱动 I/O 的可移植性也不会比 epoll 更好。

对于某些应用来说，编写一个软件抽象层来检查文件描述符事件是非常值得做的。有了这样一个抽象层，可移植的程序就能在提供有epoll 机制的系统上应用epoll（或类似的API）或者信号驱动API，而在其他系统上继续使用select()和poll()。

Libevent 库就是这样一个软件层，它提供了检查文件描述符 I/O 事件的抽象，已经移植到了多个UNIX 系统中。Libevent 的底层机制能够（以透明的方式）应用本章所描述的任意一种技术：`select()` 、`poll()` 、信号驱动I/O 或者epoll。同样，也支持Solaris 专有的/dev/poll 接口和 BSD系统的 `kqueue` 接口。

### 水平触发和边缘触发
两种文件描述符准备就绪的通知模式: 
+ 水平触发通知：如果文件描述符上可以非阻塞地执行 I/O 系统调用，此时认为它已经就绪。
+ 边缘触发通知：如果文件描述符自上次状态检查以来有了新的 I/O 活动（比如新的输入），此时需要触发通知。

当采用水平触发通知时，我们可以在任意时刻检查文件描述符的就绪状态。这表示当我们确定了文件描述符处于就绪态时（比如存在有输入数据），就可以对其执行一些 I/O 操作，然后重复检查文件描述符，看看是否仍然处于就绪态（比如还有更多的输入数据），此时我们就能执行更多的 I/O，以此类准。换句话说，由于水平触发模式允许我们在任意时刻重复检查 I/O 状态，没有必要每次当文件描述符就绪后需要尽可能多地执行 I/O （也就是尽可能多地读取字节，亦或是根本不去执行任何 I/O）。

与之相反的是，当我们采用边缘触发时，只有当I/O 事件发生时我们才会收到通知。在另一个I/O 事件到来前我们不会收到任何新的通知。另外，当文件描述符收到I/O 事件通知时，通常我们并不知道要处理多少 I/O（例如有多少字节可读）。因此，采用边缘触发通知的程序通常要按照如下规则来设计:

+ 在接收到一个 I/O 事件通知后，程序在某个时刻应该在相应的文件描述符上尽可能多地执行I/O （比如尽可能多地读取字节）。如果程序没这么做，那么就可能失去执行 I/O的机会。因为直到产生另一个 I/O 事件为止，在此之前程序都不会再接收到通知了，因此也就不知道此时应该执行 I/O 操作。这将导致数据丢失或者程序中出现阻塞。前面我们说“在某个时刻”，是因为有时候当我们确定了文件描述符是就绪态时，此时可能并不适合马上执行所有的 I/O 操作。问题的原因在于如果我们仅对一个文件描述符执行大量的 I/O 操作，可能会让其他文件描述符处于饥饿状态。

+ 如果程序采用循环来对文件描述符执行尽可能多的 I/O，而文件描述符又被置为可阻塞的，那么最终当没有更多的 I/O 可执行时，I/O 系统调用就会阻塞。基于这个原因，每个被检查的文件描述符通常都应该置为非阻塞模式，在得到I/O 事件通知后重复执行I/O 操作，直到相应的系统调用（比如 `read()` ，`write()` ）以错误码 `EAGAIN` 或 `EWOULDBLOCK` 的形式失败。


## poll 与 select 
```
int select(int nfds, fd_set *_Nullable restrict readfds,
                  fd_set *_Nullable restrict writefds,
                  fd_set *_Nullable restrict exceptfds,
                  struct timeval *_Nullable restrict timeout);

void FD_CLR(int fd, fd_set *set);
int  FD_ISSET(int fd, fd_set *set);
void FD_SET(int fd, fd_set *set);
void FD_ZERO(fd_set *set);
```
+ `nfds` : 最大文件描述符值 + 1
+ `readfds` : 监听可读事件的文件描述符集合
+ `writefds` : 监听可写事件的文件描述符集合
+ `exceptfds` : 监听异常事件的文件描述符集合
+ `timeout` : 超时时间

```
int poll(struct pollfd *fds, nfds_t nfds, int timeout);

struct pollfd {
    int   fd;         /* file descriptor */
    short events;     /* requested events */
    short revents;    /* returned events */
};
```
+ `fds` : 指向一个 `pollfd` 数组的指针
+ `nfds` : 指明 `fds` 数组的长度
+ `timeout` : 超时时间

以下是系统调用 `select()` 和 `poll()` 在 API 层面上的一些区别。
+ `select()` 所使用的数据类型 `fd_set` 对于被检查的文件描述符数量有一个上限限制（ `FD_SETSIZE` ） 。在 Linux 下，这个上限值默认为 1024，修改这个上限需要重新编译应用程序。与之相反， `poll()` 对于被检查的文件描述符数量本质上是没有限制的。
+ 由于 `select()` 的参数 `fd_set` 同时也是保存调用结果的地方，如果要在循环中重复调用select()的话，我们必须每次都要重新初始化 `fd_set` 。而 `poll()` 通过独立的两个字段 `events`（针对输入）和 `revents` （针对输出）来处理，从而避免每次都要重新初始化参数。
+ `select()` 提供的超时精度（微秒）比 `poll()` 提供的超时精度（毫秒）高。（这两个系统调用的超时精度都受软件时钟粒度的限制。
+ 如果其中一个被检查的文件描述符关闭了，通过在对应的 `revents` 字段中设定 `POLLNVAL` 标记， `poll()` 会准确告诉我们是哪一个文件描述符关闭了。与之相反， `select()` 只会返回−1，并设错误码为 `EBADF` 。通过在描述符上执行 I/O 系统调用并检查错误码，让我们自己来判断哪个文件描述符关闭了。通常这些区别都不重要，因为应用程序一般都会自己跟踪已经关闭的文件描述符。

当如满足如下两条中任意一条时，poll()和 select()将具有相似的性能表现：
+ 待检查的文件描述符范围较小（即，最大的文件描述符号较低）。
+ 有大量的文件描述符待检查，但是它们分布得很密集。（即，大部分或所有的文件描述符号都在 0 到某个上限之间）。

然而，如果被检查的文件描述符集合很稀疏的话， `select()` 和 `poll()` 的性能差异将变得非常明显。比如，最大文件描述符号 N 是个很大的整数，但在 0 到 N 之间只有 1 个或几个文件描述符要被检查。在这种情况下， `poll()` 的性能表现将优于 `select()` 。我们可以通过传递给这两个系统调用的参数来理解这其中的原因。在 `select()` 中，我们传递一个或多个文件描述符集合，以及比待检查的集合中最大的文件描述符号还要大 1 的$nfds$ 。不管我们是否要检查范围 $0 到nfds−1$之间的所有文件描述符，$nfds$的值都不变。无论哪种情况，内核都必须在每个集合中检查$nfds$个元素，以此来查明到底需要检查哪个文件描述符。与之相反，当使用 `poll()` 时，只需要指定我们感兴趣的文件描述符即可，内核只会去检查这些指定的文件描述符。

### select()和 poll()存在的问题
系统调用 `select()` 和 `poll()` 是用来同时检查多个文件描述符就绪状态的方法，它们是可移植的、长期存在且被广泛使用的。但是当检查大量的文件描述符时，这两个 API 都会遇到一些问题:
+ 每次调用 `select()` 或 `poll()` ，内核都必须检查所有被指定的文件描述符，看它们是否处于就绪态。当检查大量处于密集范围内的文件描述符时，该操作耗费的时间将大大超过接下来的操作。
+ 每次调用 `select()` 或 `poll()` 时，程序都必须传递一个表示所有需要被检查的文件描述符的数据结构到内核，内核检查过描述符后，修改这个数据结构并返回给程序。（此外，对于 `select()` 来说，我们还必须在每次调用前初始化这个数据结构。）对于 `poll()` 来说，随着待检查的文件描述符数量的增加，传递给内核的数据结构大小也会随之增加。当检查大量文件描述符时，从用户空间到内核空间来回拷贝这个数据结构将占用大量的 CPU 时间。对于 `select()` 来说，这个数据结构的大小固定为 `FD_SETSIZE` ，与待检查的文件描述符数量无关。
+ `select(` )或 `poll()` 调用完成后，程序必须检查返回的数据结构中的每个元素，以此查明哪个文件描述符处于就绪态了。


## epoll
epoll操作过程需要三个接口，分别如下：
```
int epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；
int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
```

1. `int epoll_create(int size);` 
    
   创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于`select()`中的第一个参数，给出最大监听的fd+1的值，参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。 当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看`/proc/进程id/fd/`，是能够看到这个fd的，所以在使用完epoll后，必须调用`close()`关闭，否则可能导致fd被耗尽。

2. `int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；`  

   函数是对指定描述符fd执行op操作:
    + `epfd` ：是epoll_create()的返回值。
    + `op` ：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。
    + `fd` ：是需要监听的fd（文件描述符）
    + `epoll_event` ：是告诉内核需要监听什么事，struct epoll_event结构如下：
      ```
      struct epoll_event {
        __uint32_t events;  /* Epoll events */
        epoll_data_t data;  /* User data variable */
      };
      ```
      events可以是以下几个宏的集合：
      + EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；
      + EPOLLOUT：表示对应的文件描述符可以写；
      + EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；
      + EPOLLERR：表示对应的文件描述符发生错误；
      + EPOLLHUP：表示对应的文件描述符被挂断；
      + EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。
      + EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里

3. `int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);`  

   等待epfd上的io事件，最多返回maxevents个事件。  
   参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。


性能对照：
<center><img src="pics/epoll.png" alt=""></center>

### epoll 高性能的原因
在我们看看为什么 epoll 的性能表现会更好:
+ 每次调用 `select()` 和 `poll()` 时，内核必须检查所有在调用中指定的文件描述符。与之相反，当通过 `epoll_ctl()` 指定了需要监视的文件描述符时，内核会在与打开的文件描述上下文相关联的列表中记录该描述符。之后每当执行 I/O 操作使得文件描述符成为就绪态时，内核就在 epoll 描述符的就绪列表中添加一个元素。（单个打开的文件描述上下文中的一次 I/O 事件可能导致与之相关的多个文件描述符成为就绪态。）之后的 `epoll_wait()` 调用从就绪列表中简单地取出这些元素。
+ 每次调用 `select()` 或 `poll()` 时，我们传递一个标记了所有待监视的文件描述符的数据结构给内核，调用返回时，内核将所有标记为就绪态的文件描述符的数据结构再传回给我们。与之相反，在 epoll 中我们使用 `epoll_ctl()` 在内核空间中建立一个数据结构，该数据结构会将待监视的文件描述符都记录下来。一旦这个数据结构建立完成，稍后每次调用 `epoll_wait()` 时就不需要再传递任何与文件描述符有关的信息给内核了，而调用返回的信息中只包含那些已经处于就绪态的描述符。