#  字符编码
{docsify-updated}

在计算机中，所有数据都是以二进制数的形式存储的，字符 char 也不例外。为了表示字符，我们需要建立一套“字符集”，规定每个字符和二进制数之间的一一对应关系。有了字符集之后，计算机就可以通过查表完成二进制数到字符的转换。

字符（character） → 有一个唯一的码点（code point） → 根据编码方案（如 UTF-8/UTf-16/UTF-32）转换为一串 字节（bytes）。

## ASCII 字符集
「ASCII 码」是最早出现的字符集，其全称为 American Standard Code for Information Interchange（美国标准信息交换代码）。它使用 7 位二进制数（一个字节的低 7 位）表示一个字符，最多能够表示 128 个不同的字符。如图 3‑6 所示，ASCII 码包括英文字母的大小写、数字 0 ~ 9、一些标点符号，以及一些控制字符（如换行符和制表符）。
<center><img src="pics/ascii.png" width="50%"></center>

然而，ASCII 码仅能够表示英文。随着计算机的全球化，诞生了一种能够表示更多语言的「EASCII」字符集。它在 ASCII 的 7 位基础上扩展到 8 位，能够表示 256 个不同的字符。在世界范围内，陆续出现了一批适用于不同地区的 EASCII 字符集。这些字符集的前 128 个字符统一为ASCII 码，后 128 个字符定义不同，以适应不同语言的需求。

## ANSI 字符集
ANSI是一种字符代码，为使计算机支持更多语言，通常使用 0x00-0x7f（即0000 0000-0111 1111）范围的1 个字节来表示1个英文字符。超出此范围的使用0x80-0xFFFF（即 1000 0000-1111 1111 1111 1111）来编码，即扩展的ASCII编码。

为使计算机支持更多语言，通常使用 0x80-0xFFFF 范围的 2 个字节来表示1个字符。比如：汉字 '中' 在中文操作系统中，使用 [0xD6,0xD0] 这两个字节存储。  
不同的国家和地区制定了不同的标准，由此产生了 GB2312、GBK、GB18030、Big5、Shift_JIS 等各自的编码标准。这些使用多个字节来代表一个字符的各种汉字延伸编码方式，称为 ANSI 编码。
+ 在简体中文Windows操作系统中，ANSI 编码代表 GBK 编码；
+ 在繁体中文Windows操作系统中，ANSI编码代表Big5；
+ 在日文Windows操作系统中，ANSI 编码代表 Shift_JIS 编码。

不同 ANSI 编码之间互不兼容，当信息在国际间交流时，无法将属于两种语言的文字，存储在同一段 ANSI 编码的文本中。
ANSI编码表示英文字符时用一个字节，表示中文用两个或四个字节。

### 汉字编码
中国国家标准总局于 1980 年发布了「GB2312」字符集，其收录了 6763 个汉字，基本满足了汉字的计算机处理需要。  
然而，GB2312 无法处理部分罕见字和繁体字。「GBK」字符集是在 GB2312 的基础上扩展得到的，它共收录了 21886 个汉字。在 GBK 的编码方案中，ASCII 字符使用一个字节表示，汉字使用两个字节表示。  
GB 18030，全称《信息技术 中文编码字符集》，是中华人民共和国国家标准所规定的变长多字节字符集。其对GB 2312-1980完全向后兼容，与GBK基本向后兼容，并支持Unicode（GB 13000）的所有码位。


##  Unicode 字符集
随着计算机技术的蓬勃发展，字符集与编码标准百花齐放，而这带来了许多问题。一方面，这些字符集一般只定义了特定语言的字符，无法在多语言环境下正常工作。另一方面，同一种语言存在多种字符集标准，如果两台计算机使用的是不同的编码标准，则在信息传递时就会出现乱码。那个时代的研究人员就在想：如果推出一个足够完整的字符集，将世界范围内的所有语言和符号都收录其中，不就可以解决跨语言环境和乱码问题了吗？在这种想法的驱动下，一个大而全的字符集 Unicode 应运而生。

「Unicode」的中文名称为“统一码”，理论上能容纳 100 多万个字符。它致力于将全球范围内的字符纳入统一的字符集之中，提供一种通用的字符集来处理和显示各种语言文字，减少因为编码标准不同而产生的乱码问题。

自 1991 年发布以来，Unicode 不断扩充新的语言与字符。截至 2022 年 9 月，Unicode 已经包含 149186 个字符，包括各种语言的字符、符号甚至表情符号等。在庞大的 Unicode 字符集中，常用的字符占用 2 字节，有些生僻的字符占用 3 字节甚至 4 字节。

Unicode 是一种通用字符集，本质上是给每个字符分配一个编号（称为“码点”），但它并没有规定在计算机中如何存储这些字符码点。我们不禁会问：当多种长度的 Unicode 码点同时出现在一个文本中时，系统如何解析字符？例如给定一个长度为 2 字节的编码，系统如何确认它是一个 2 字节的字符还是两个 1 字节的字符？

对于以上问题，一种直接的解决方案是将所有字符存储为等长的编码。“Hello”中的每个字符占用 1 字节，“算法”中的每个字符占用 2 字节。我们可以通过高位填 0 将“Hello 算法”中的所有字符都编码为 2 字节长度。这样系统就可以每隔 2 字节解析一个字符，恢复这个短语的内容了。

然而 ASCII 码已经向我们证明，编码英文只需 1 字节。若采用上述方案，英文文本占用空间的大小将会是ASCII 编码下的两倍，非常浪费内存空间。因此，我们需要一种更加高效的 Unicode 编码方法。

### UTF-8编码
目前，UTF‑8 已成为国际上使用最广泛的 Unicode 编码方法。它是一种可变长度的编码，使用 1 到 4 字节来表示一个字符，根据字符的复杂性而变。ASCII 字符只需 1 字节，拉丁字母和希腊字母需要 2 字节，常用的中文字符需要 3 字节，其他的一些生僻字符需要 4 字节。

UTF‑8 的编码规则并不复杂，分为以下两种情况：
+ 对于长度为 1 字节的字符，将最高位设置为 0 ，其余 7 位设置为 Unicode 码点。值得注意的是，ASCII字符在 Unicode 字符集中占据了前 128 个码点。也就是说，UTF‑8 编码可以向下兼容 ASCII 码。这意味着我们可以使用 UTF‑8 来解析年代久远的 ASCII 码文本。
+ 对于长度为 𝑛 字节的字符（其中 𝑛 > 1），将首个字节的高 𝑛 位都设置为 1 ，第 𝑛 + 1 位设置为 0 ；从第二个字节开始，将每个字节的高 2 位都设置为 10 ；其余所有位用于填充字符的 Unicode 码点。

但为什么要将其余所有字节的高 2 位都设置为 10 呢？实际上，这个 10 能够起到校验符的作用。假设系统从一个错误的字节开始解析文本，字节头部的 10 能够帮助系统快速判断出异常。

之所以将 10 当作校验符，是因为在 UTF‑8 编码规则下，不可能有字符的最高两位是 10 。这个结论可以用反证法来证明：假设一个字符的最高两位是 10 ，说明该字符的长度为 1 ，对应 ASCII 码。而 ASCII 码的最高位应该是 0 ，与假设矛盾。

<!-- <center><img src="pics/utf-8.png" width="60%"></center> -->

+ 算--> U+7B97(\u7b97) --> 0111 1011 1001 0111
+ 法--> U+6CD5(\u6cd5) --> 0110 1100 1101 0101

除了 UTF‑8 之外，常见的编码方式还包括以下两种。
+ UTF‑16 编码：使用 2 或 4 字节来表示一个字符。所有的 ASCII 字符和常用的非英文字符，都用 2 字节表示；少数字符需要用到 4 字节表示。对于 2 字节的字符，UTF‑16 编码与 Unicode 码点相等。
+ UTF‑32 编码：每个字符都使用 4 字节。这意味着 UTF‑32 比 UTF‑8 和 UTF‑16 更占用空间，特别是对于 ASCII 字符占比较高的文本。

从存储空间占用的角度看，使用 UTF‑8 表示英文字符非常高效，因为它仅需 1 字节；使用 UTF‑16 编码某些非英文字符（例如中文）会更加高效，因为它仅需 2 字节，而 UTF‑8 可能需要 3 字节。从兼容性的角度看，UTF‑8 的通用性最佳，许多工具和库优先支持 UTF‑8 。

UTF-8编码：

| 码点范围（十六进制）     | 字节数 | UTF-8 编码格式                            |
|--------------------------|--------|-------------------------------------------|
| U+0000 ~ U+007F          | 1      | 0xxxxxxx （兼容 ASCII）                   |
| U+0080 ~ U+07FF          | 2      | 110xxxxx 10xxxxxx                         |
| U+0800 ~ U+FFFF          | 3      | 1110xxxx 10xxxxxx 10xxxxxx                |
| U+10000 ~ U+10FFFF       | 4      | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx       |


### UTF-8、UTF-8-BOM、UTF-16-BE、UTF-16-LE
BOM 是 byte-order mark 的缩写，是 "字节序标记" 的意思, 它常被用来当做标识**文件**（注意是用来标记文件的，与字符编码无关）是以 UTF-8、UTF-16 或 UTF-32 编码的标记.

在 Unicode 编码中有一个叫做 "零宽度非换行空格" 的字符 ( ZERO WIDTH NO-BREAK SPACE ), 用字符 FEFF 来表示：
+ 对于 UTF-16 ，如果接收到以 `FEFF` 开头的字节流， 就表明是大端字节序，如果接收到 `FFFE` ， 就表明字节流 是小端字节序  
+ UTF-8 没有字节序问题，上述字符只是用来标识它是 UTF-8 文件，而不是用来说明字节顺序的。"零宽度非换行空格" 字符 的 UTF-8 编码是 EF BB BF, 所以如果接收到以 EF BB BF 开头的字节流，就知道这是UTF-8 文件

下面的表格列出了不同 UTF 格式的固定文件头
|UTF编码 | 固定文件头|
|----|------|
| UTF-8-BOM|	EF BB BF|
| UTF-16LE|	FF FE|
| UTF-16BE|	FE FF|
| UTF-32LE|	FF FE 00 00|
| UTF-32BE|	00 00 FE FF|

"你好" 两个字在不同编码场景下，保存在磁盘上的数据是不同的：
<center><img src="pics/encode.jpg" width="40%"></center>

"你好" 在Java 内存中的表示（UTF-16）：
<center><img src="pics/encode-2.jpg" width="40%"></center>

```
String s = "你好";
System.out.println(s);
Files.write(Path.of("./test2.txt"),s.getBytes("UTF-16"));
Files.write(Path.of("./test.txt"),s.getBytes("UTF-8"));
```
<center><img src="pics/java-encode.jpg" width="40%"></center>


有两个概念对于理解Unicode至关重要：
+ **码点**是代表Unicode文本的原子数字。它们大多代表可见的符号，但也可以有其他含义，如指定一个符号的某个方面（一个字母的重音，一个表情符号的肤色，等等）。
+ **代码单位**是编码码点的数字，是码点的具体存储表示方式，用于存储或传输Unicode文本。一个或多个代码单元编码一个代码点。每个代码单元都有相同的大小，这取决于所使用的编码格式。最流行的格式，UTF-8，有8位代码单元。

通俗的理解码点是一个字符/符号在某种编码标准中（Unicode/Big5/ASCII..）映射为一个数字的数值，一个码点对应一个符号。代码单元是表示码点的具体方式，比如在计算机中可以用反码/补码表示一个数字，用一个字节或者两个字节存储。

下面利用一些专用术语解释一下Java语言解决这个问题的基本方法。从JDK5.0开始。**代码点(code point)是指与一个编码表中的某个字符对应的代码值**。在Unicode标准中，代码点采用十六进制书写，并加上前缀U+，例如U+0041就是字母A的代码点。Unicode的代码点可以分成17个代码级別(code plane)。第一个代码级别称为基本的多语言级别(basic multilingual plane)，代码点从U+0000到U+FFFF，其中包括了经典的Unicode代码;其余的16个附加级别，代码点从U+10000到U+10FFFF，其中包括了一些辅助宇符(supplementary character).

UTF-16编码采用不同长度的编码表示所有Unicode代码点。**在基本的多语言级别中，每个字符用16位（2字节）表示，通常被称为代码单元(code unit):而辅助字符采用一对连续的代码单元进行编码**。这样构成的编码值一定落人基本的多语言级别中空闲的2048字节内，通常被称为替代区域(surrogatearea)，U+D800 - U+DBFF用于第一个代码单元，U+DCOO - U+DFFF用于第二个代码单元。这样设计十分巧妙，我们可以从中迅速地知道一个代码单元是一个字符的编码，还是一个辅助字符的第一或第二部分。例如，对于整数集合的数学符号石，它的代码点是U+1D56B，并且是用两个代码单元U+D835和U+DD6B编码的(有关编码算法的描述请参看http://en.wikipe-dia.org/wiki/UTF-16)。


JAVA中，char 数据类型是一个采用UTF-16编码表示Unicode代码点的代码单元。大多数的常用Unicode 字符使用一个代码单元（2字节）就可以表示，而辅助字符需要一对代码单元（4字节）表示。
String 的 length 方法将返回采用UTF-16编码表示的给定宇符串所需要的代码单元数量。

## Unicode 转义
Unicode 中每个字符都有唯一的 码点（code point），可以写成：
```
\uXXXX  →  XXXX 是字符的 16 进制编码（长度为 4 位）
```

例子：
| 字符 | Unicode 编码 | Unicode 转义表示                |
|------|---------------|---------------------------------|
| A    | U+0041        | \u0041                         |
| 中   | U+4E2D        | \u4E2D                         |
| 😀   | U+1F600       | \uD83D\uDE00   |


## 文件与文件编码
绝大多数 文本文件本身并不保存编码信息，文件的编码通常由文件内容的字节序列 + 解释方式共同决定。文件编码是“约定”而非“内嵌元数据”，除非明确加入特殊标记（如 BOM）。

+ ✅ 文件内容是字节流，没有“编码声明”
+ ❌ 不会自动包含“我是 UTF-8”或“我是 GBK”的元信息
+ ⚠️ 编码必须靠：
+ 文件开头是否带有 BOM（Byte Order Mark）
+ 外部系统（编辑器、解释器）做出假设或配置

| 误解                                       | 实际情况                                                                 |
|--------------------------------------------|--------------------------------------------------------------------------|
| “文本文件保存时会记录它是什么编码”        | ❌ 除非加 BOM，否则不会记录                                              |
| “用 VS Code 保存成 UTF-8，别人打开就知道” | ❌ 对方编辑器必须同样设置 UTF-8，否则可能乱码                            |
| “系统自动知道 GBK 文件的编码”              | ❌ 系统不知道，必须你告诉它或用检测工具猜测                              |